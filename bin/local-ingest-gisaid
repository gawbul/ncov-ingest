#!/usr/bin/env bash
# usage: local-ingest-gisaid [flags]
#        local-ingest-gisaid --help
#
# flags:
#
#  --help             Print this help message
#
#  --download-inputs  Download required input files from AWS S3 bucket
#                     (Note: required gisaid.ndjson file should be downloaded
#                     separately)
#
#  --ingest           Run ingest scripts offline locally. This will take input
#                     files, perform transformations and will write output files
#
#  --upload-outputs   Upload output files to AWS S3 bucket
#
# shellcheck disable=SC1091

set -o errexit
set -o nounset
set -o pipefail
trap "exit" INT

TMP_DIR="data/gisaid/tmp"
INPUT_DIR="data/gisaid/inputs"
OUTPUT_DIR="data/gisaid/outputs"

GISAID_NDJSON="${INPUT_DIR}/gisaid.ndjson"

METADATA_OLD="${INPUT_DIR}/metadata.tsv"
METADATA_NEW="${OUTPUT_DIR}/metadata.tsv"
METADATA_CHANGES="${OUTPUT_DIR}/metadata-changes.txt"
METADATA_ADDITIONS="${OUTPUT_DIR}/metadata-additions.tsv"

ADDITIONAL_INFO_OLD="${INPUT_DIR}/additional_info.tsv"
ADDITIONAL_INFO_NEW="${OUTPUT_DIR}/additional_info.tsv"
ADDITIONAL_INFO_CHANGES="${OUTPUT_DIR}/additional-info-changes.txt"

S3_BUCKET="s3://nextstrain-ncov-private"

KEY="gisaid_epi_isl"

main() {
  cd "$(dirname "$0")/.."

  for arg; do
    case "$arg" in
    -h | --help)
      print-help
      exit
      ;;
    --download-inputs)
      download-inputs
      exit
      ;;
    --download-gisaid)
      download-gisaid
      exit
      ;;
    --transform)
      transform
      exit
      ;;
    --ingest)
      ingest
      exit
      ;;
    --upload-outputs)
      upload-outputs
      exit
      ;;
    esac
  done

  print-help
}

download-inputs() {
  mkdir -p "${INPUT_DIR}"

  ./bin/download-from-s3 "${S3_BUCKET}/additional_info.tsv.gz" "data/gisaid/inputs/additional_info.tsv"
  ./bin/download-from-s3 "${S3_BUCKET}/metadata.tsv.gz" "data/gisaid/inputs/metadata.tsv"
}

download-gisaid() {
  [ -f ".env" ] && source ".env"
  [ -f "../.env" ] && source "../.env"

  mkdir -p "${INPUT_DIR}"
  mkdir -p "${TMP_DIR}"

  wget \
    --directory-prefix="${TMP_DIR}" \
    --http-user="${GISAID_USERNAME}" \
    --http-password="${GISAID_PASSWORD}" \
    "${GISAID_URL}" \
    -O "${TMP_DIR}/gisaid.ndjson.bz2"

  bzip2 -cdk "${TMP_DIR}/gisaid.ndjson.bz2" >"${GISAID_NDJSON}"
}

transform() {
  mkdir -p "${OUTPUT_DIR}"

  ./bin/transform-gisaid "${INPUT_DIR}/gisaid.ndjson" \
    --output-metadata "${OUTPUT_DIR}/metadata.tsv" \
    --output-fasta "${OUTPUT_DIR}/sequences.fasta" \
    --output-additional-info "${OUTPUT_DIR}/additional_info.tsv"
}

ingest() {
  mkdir -p "${OUTPUT_DIR}"

  ./bin/transform-gisaid "${INPUT_DIR}/gisaid.ndjson" \
    --output-metadata "${OUTPUT_DIR}/metadata.tsv" \
    --output-fasta "${OUTPUT_DIR}/sequences.fasta" \
    --output-additional-info "${OUTPUT_DIR}/additional_info.tsv"

  # Find sequences in FASTA which don't have clades assigned yet
  ./bin/filter-fasta \
    --input_fasta="${OUTPUT_DIR}/sequences.fasta" \
    --input_tsv="${INPUT_DIR}/nextclade.tsv" \
    --output_fasta="${OUTPUT_DIR}/nextclade.sequences.fasta"

  # ... and assign clades to them
  ./bin/run-nextclade \
    "${OUTPUT_DIR}/nextclade.sequences.fasta" \
    "${INPUT_DIR}/nextclade.tsv" \
    "${OUTPUT_DIR}/nextclade.tsv"

  # Join these clades into metadata
  ./bin/join-metadata-and-clades \
    "${OUTPUT_DIR}/metadata.tsv" \
    "${OUTPUT_DIR}/nextclade.tsv" \
    -o "${OUTPUT_DIR}/metadata.tsv"

  csv-diff \
    "${METADATA_OLD}" \
    "${METADATA_NEW}" \
    --format tsv \
    --key "$KEY" \
    --singular sequence \
    --plural sequences \
    >"${METADATA_CHANGES}"

  ./bin/metadata-additions "${METADATA_OLD}" "${METADATA_NEW}" "${KEY}" >"${METADATA_ADDITIONS}"

  csv-diff \
    <(awk 'BEGIN {FS="\t"}; { if ($3 != "" || $4 != "") { print }}' "${ADDITIONAL_INFO_OLD}") \
    <(awk 'BEGIN {FS="\t"}; { if ($3 != "" || $4 != "") { print }}' "${ADDITIONAL_INFO_NEW}") \
    --format tsv \
    --key "${KEY}" \
    --singular "additional info" \
    --plural "additional info" \
    >${ADDITIONAL_INFO_CHANGES}

  ./bin/flag-metadata "${OUTPUT_DIR}/metadata.tsv" >"${OUTPUT_DIR}/flagged_metadata.txt"

}

upload-outputs() {
  ./bin/upload-to-s3 "${OUTPUT_DIR}/metadata.tsv" "${S3_BUCKET}/metadata.tsv.gz"
  ./bin/upload-to-s3 "${OUTPUT_DIR}/additional_info.tsv" "${S3_BUCKET}/additional_info.tsv.gz"
  ./bin/upload-to-s3 "${OUTPUT_DIR}/flagged_metadata.txt" "${S3_BUCKET}/flagged_metadata.txt.gz"
  ./bin/upload-to-s3 "${OUTPUT_DIR}/sequences.fasta" "${S3_BUCKET}/sequences.fasta.xz"

  # Parallel uploads of zstd compressed files to slowly transition to this format
  ./bin/upload-to-s3 "${OUTPUT_DIR}/metadata.tsv" "${S3_BUCKET}/metadata.tsv.zst"
  ./bin/upload-to-s3 "${OUTPUT_DIR}/additional_info.tsv" "${S3_BUCKET}/additional_info.tsv.zst"
  ./bin/upload-to-s3 "${OUTPUT_DIR}/flagged_metadata.txt" "${S3_BUCKET}/flagged_metadata.txt.zst"
  ./bin/upload-to-s3 "${OUTPUT_DIR}/sequences.fasta" "${S3_BUCKET}/sequences.fasta.zst"
}

print-help() {
  # Print the help comments at the top of this file ($0)
  local line
  while read -r line; do
    if [[ $line =~ ^#! ]]; then
      continue
    elif [[ $line =~ ^# ]]; then
      line="${line/##/}"
      line="${line/# /}"
      echo "$line"
    else
      break
    fi
  done <"$0"
}

main "$@"
